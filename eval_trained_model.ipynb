{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "import os \n",
    "import utils\n",
    "import mlmodel\n",
    "\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_a = 3\n",
    "\n",
    "dim_a = 16\n",
    "\n",
    "features = ['q', 'q_dot', 'tau_cmd']\n",
    "label = 'tau_residual_cmd'\n",
    "\n",
    "labels = [\"FR_hip\", \"FR_knee\", \"FR_foot\", \"FL_hip\", \"FL_knee\", \"FL_foot\",\n",
    "          \"RR_hip\", \"RR_knee\", \"RR_foot\", \"RL_hip\", \"RL_knee\", \"RL_foot\"]\n",
    "\n",
    "# Training data collected from the neural-fly drone\n",
    "dataset = 'rina' \n",
    "dataset_folder = '/home/hcr/Research/DARoSLab/DARoS-Core/lcm_converted_log/05_17_2024_formal/eval_data/'\n",
    "\n",
    "# dataset_folder = \"/home/oyoungquist/Research/RINA/rina/data/lcm_converted_log/05_17_2024_formal/eval_data/\"\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "output_path_base = os.path.join(cwd, \"training_results\", \"06_18_202410_33_48_cmd_residual_3rd_tune_half_128\")\n",
    "\n",
    "modelname = f\"{dataset}_dim-a-{dim_a}_{'-'.join(features)}\" # 'intel-aero_fa-num-Tsp_v-q-pwm'\n",
    "\n",
    "print(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RawData = utils.load_data(dataset_folder)\n",
    "# TestData = utils.format_data(RawData, features=features, output=label, body_offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_images = os.path.join(output_path_base, \"eval_condition_data_images\")\n",
    "\n",
    "# if not os.path.exists(test_data_images):\n",
    "#     os.makedirs(test_data_images)\n",
    "\n",
    "# for data in TestData:\n",
    "#     print(data.meta['condition'])\n",
    "#     utils.plot_subdataset(data, features, labels, os.path.join(test_data_images, \"{:s}.png\".format(data.meta['condition'])), title_prefix=\"(Testing Data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {}\n",
    "# options['dim_x'] = TestData[0].X.shape[1]\n",
    "# options['dim_y'] = TestData[0].Y.shape[1]\n",
    "# options['num_c'] = len(TestData)\n",
    "\n",
    "options['dim_x'] = 36\n",
    "options['dim_y'] = 12\n",
    "options['num_c'] = 3\n",
    "\n",
    "print('dims of (x, y) are', (options['dim_x'], options['dim_y']))\n",
    "print('there are ' + str(options['num_c']) + ' different conditions')\n",
    "\n",
    "# Set hyperparameters\n",
    "options['features'] = features\n",
    "options['dim_a'] = dim_a\n",
    "options['loss_type'] = 'crossentropy-loss'\n",
    "\n",
    "options['shuffle'] = True # True: shuffle trajectories to data points\n",
    "options['K_shot'] = 32 # number of K-shot for least square on a\n",
    "options['phi_shot'] = 256 # batch size for training phi\n",
    "\n",
    "options['alpha'] = 0.01 # adversarial regularization loss2\n",
    "options['learning_rate'] = 5e-4\n",
    "options['frequency_h'] = 2 # how many times phi is updated between h updates, on average\n",
    "options['SN'] = 2. # maximum single layer spectral norm of phi\n",
    "options['gamma'] = 10. # max 2-norm of a\n",
    "options['num_epochs'] = 2000\n",
    "\n",
    "\n",
    "options['phi_first_out'] = 128\n",
    "options['phi_second_out'] = 128\n",
    "options['discrim_hidden'] = 50\n",
    "\n",
    "\n",
    "options['output_path'] = output_path_base\n",
    "options['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"rina_dim-a-16_q-q_dot-tau_cmd\"\n",
    "# model_path = os.path.join(\"/home/oyoungquist/Research/RINA/rina/training_results/06_18_202410_33_48_cmd_residual_3rd_tune_half_128/models\", (modelname + '-epoch-' + str(2000)))\n",
    "model_path = os.path.join(\"/home/hcr/Research/DARoSLab/rina/training_results/06_18_202410_33_48_cmd_residual_3rd_tune_half_128/models\", (modelname + '-epoch-' + str(2000)))\n",
    "final_model = mlmodel.load_model(modelname = model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi_net = final_model.phi\n",
    "# h_net = final_model.h\n",
    "\n",
    "# eval_adapt_start = 0\n",
    "# eval_adapt_end = 2500\n",
    "# eval_val_start = 2500\n",
    "# eval_val_end = 5000\n",
    "\n",
    "# # vis_output_path_prefix_training_data = os.path.join(options[\"output_path\"], \"eval_iamges\", \"training\")\n",
    "# # vis_output_path_prefix_testing_data = os.path.join(options[\"output_path\"], \"eval_iamges\", \"testing\")\n",
    "\n",
    "# # vis_output_path_prefix_training_data = os.path.join(\"/home/hcr/Research/DARoSLab/rina/training_results/06_03_202411_37_13_cmd_residual_2nd_tune/eval_condition_images/training\")\n",
    "# # vis_output_path_prefix_testing_data = os.path.join(\"/home/hcr/Research/DARoSLab/rina/training_results/06_03_202411_37_13_cmd_residual_2nd_tune/eval_condition_images/testing\")\n",
    "# vis_output_path_prefix_testing_data = os.path.join(\"/home/oyoungquist/Research/RINA/rina/training_results/06_03_202411_37_13_cmd_residual_2nd_tune/eval_condition_images/testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(TestData):\n",
    "#     print('------------------------------')\n",
    "#     print(data.meta['condition'] + ':')\n",
    "#     print(len(data.X))\n",
    "#     file_name = \"{:s}.png\".format(data.meta['condition'])\n",
    "#     mlmodel.vis_validation(t=data.meta['steps'], x=data.X, y=data.Y, phi_net=phi_net, h_net=h_net, \n",
    "#                            idx_adapt_start=eval_adapt_start, idx_adapt_end=eval_adapt_end, \n",
    "#                            idx_val_start=eval_val_start, idx_val_end=eval_val_end, c=TestData[i].C, options=options,\n",
    "#                            output_path_prefix=vis_output_path_prefix_testing_data, output_name=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in TestData:\n",
    "#     image_name = \"{:s}_errors_hist.png\".format(data.meta['condition'])\n",
    "#     error_1, error_2, error_3 = mlmodel.error_statistics_hist(data.X, data.Y, phi_net, h_net, options, vis_output_path_prefix_testing_data, image_name)\n",
    "#     print('**** :', data.meta['condition'], '****')\n",
    "#     print(f'Before learning: MSE is {error_1: .2f}')\n",
    "#     print(f'Mean predictor: MSE is {error_2: .2f}')\n",
    "#     print(f'After learning phi(x): MSE is {error_3: .2f}')\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model.phi.options['device'])\n",
    "final_model.phi.options['device'] = 'cpu'\n",
    "final_model.phi.options['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_net = final_model.phi.to('cpu')\n",
    "\n",
    "# convert the trained python model to a Torch.Script model\n",
    "# An example input you would normally provide to your model's forward() method.\n",
    "example = torch.rand(1, 36)\n",
    "\n",
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(phi_net, example)\n",
    "\n",
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(phi_net, example)\n",
    "\n",
    "# testing the traced output\n",
    "print(traced_script_module(example))\n",
    "\n",
    "# save-out the scripted model\n",
    "traced_script_module.save(\"traced_rina_model_cmd_error_dima_16_128_cpu.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
